---
title: "LLM Idea"
date: 2025-11-09 10:47:00 +0900
categories: LLM, Idea
---

1. Summarize the famous AI conference.    
ex) CVPR2025    
1. Download every papers.
2. Make them into one pdf or md format.
3. Transform it to graph using like a neo4j.
4. Analyze them, Word cloud, category, nationality of authors.

Impact
- Nationality of authors: AI power of each nation.
- Analyzing the all submitted papers and accepted papers: which category is trend and hot in academic. and we could check out including industry research power.    
- Curating and Nevigating like a secretary: using the present time schedule, recommend the presents for the user using the query. This service will guide the visitors.
- Proactive recruitment: if you want to meet or find a contact researcher to recruit, this will be useful.





2. Analyze electricity.
Make a virtual world and analyze the electricity.    
decision makers can use this SW to predict how much electricty we need if a data center constructed region by region.



3. SESAME workshop short paper
Beyond Pattern Matching: Why LLMs Fail at Relational Author-Affiliation Extraction (패턴 매칭을 넘어서: LLM은 왜 관계형 저자-소속 추출에 실패하는가)

Abstract (초록)
Large Language Models (LLMs) show immense promise for automating metadata extraction in digital libraries. However, in our application of building a scholarly knowledge graph, we found that LLMs are surprisingly unreliable in the critical task of structuring author and affiliation data. This paper argues that this failure is not merely a performance flaw but a fundamental misunderstanding of the task. We demonstrate that author-affiliation extraction is not a single natural language problem but a composite of distinct, rule-based patterns, some of which require symbolic and relational reasoning. We present a taxonomy of these patterns, from simple 'inline' text to complex 'N:M numeric-key references'. Our preliminary analysis shows LLMs excel at simple patterns but catastrophically fail at relational ones. We conclude that LLMs alone are insufficient and must be integrated with structured knowledge graphs (KGs) and validators to handle the symbolic logic inherent in scholarly metadata.

(LLM은 학술 메타데이터 자동화에 유망합니다. 그러나 저희는 LLM이 저자-소속 구조화에 놀랍도록 신뢰할 수 없음을 발견했습니다. 본 논문은 이 실패가 단순한 성능 결함이 아니라, LLM이 해당 과업을 근본적으로 오해하기 때문이라고 주장합니다. 저자-소속 추출은 단일 NLP 문제가 아니라, 일부는 기호적/관계형 추론을 요구하는 별개의 규칙 기반 패턴의 복합체임을 보입니다. 저희는 단순 '인라인' 텍스트부터 복잡한 'N:M 숫자 키 참조'에 이르는 패턴 분류(taxonomy)를 제시합니다. LLM은 단순 패턴에는 뛰어나지만 관계형 패턴에서는 치명적인 실패를 보였습니다. 결론적으로 LLM 단독으로는 불충분하며, 학술 메TA데이터에 내재된 기호적 논리를 처리하기 위해 지식 그래프(KG) 및 검증기와 통합되어야 합니다.)



1. paper download
2. PyMuPDF로 Title, Author and affiliations, Abstract 정보 추출
3. Author와 Affiliations 정보를 알맞게 mapping해야함.
4. 논문의 저자들이 다양한 방법으로 해당 영역을 작성하는데, LLM은 기호로 연결된 것을 잘 이해하지 못함. 그래서, 가능한 패턴들을 사람이 먼저 분류하고 LLM에게 각각의 패턴에 맞는 방법으로 author: affiliations 정보를 mapping하도록 시켜야함.    


javascript로 만들어진 website에서 데이터를 추출하기 위해서는 동적 컨텐츠를 이해해야함.    
껍데기가 HTML로 감싸져있는 상태에서 내부에는 Javascript코드가 API를 호출하는 형태에서는 html 정보를 가져와도 내부의 동적 컨텐츠가 아직 불러와지지 않거나 완성되지 않았을 수 있음.    
그렇기 때문에, 웹사이트에서 해당 작업을 위해 어떤 call을 보내고 paprameter는 뭐가 필요한지 알아야 알맞은 대응을 할 수 있다.    



4. Github issue manager
유명한 github repository에 올라와있는 수많은 issue들을 관리할때 사용하는 manager.
task1. open issue clustering and similarity    
open issue 데이터를 다운로드받아서 DB로 만듦.
 -> 본문 전체 텍스트 가져오도록 해야할까? 이미지는 OCR로 데이터 추출? 댓글 데이터는?   
LLM으로 text embedding함.
DBSCAN 라이브러리로 clustering.
Streamlit으로 cluster UMAP으로 보여줌.
Pandas dashboard로 cluster별로 어떤 issue들이 있는지 확인하고 처리할지 논의가능.    

task2. open and closed issue similarity    
open issue DB와 closed issue DB 구축    
open issue에서 closed issue DB와 similarity 높은 것 계산 (faiss)    
